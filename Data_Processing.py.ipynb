{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing:\n",
    "\n",
    "This code takes takes out:\n",
    "1. capitalizations\n",
    "2. punctuation characters, \n",
    "3. transforms emoticons to EMOTIC_NEG or EMOTIC_POS.\n",
    "4. corrects words so that instead of goooolll is gol as example.\n",
    "5. Remove URL\n",
    "6. Remove mentions preceeding @ \n",
    "\n",
    "\n",
    "Data contains tweets with values 0=negative,2=neutral and 4=positive.\n",
    "We will be only focusing in binary negative,positive. \n",
    "\n",
    "Citation for data: Go, A., Bhayani, R. and Huang, L., 2009. Twitter sentiment classification using distant supervision. CS224N Project Report, Stanford, 1(2009), p.12.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import packages\n",
    "import itertools\n",
    "import re\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from string import punctuation\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import enchant\n",
    "\n",
    "\n",
    "######METHODS#######\n",
    "\n",
    "\n",
    "def Process(tweet):\n",
    "    tok = WordPunctTokenizer()\n",
    "\n",
    "    '''Used to process each tweet to remove capitalizations, gramatical errors and stop words'''\n",
    "    stopwordlist = set(stopwords.words(\"english\"))\n",
    "    d  =enchant.Dict(\"en_US\")\n",
    "    \n",
    "    \n",
    "    #Remove URL links\n",
    "    tweet=re.sub('https?://[A-Za-z0-9./]+','',tweet)\n",
    "    \n",
    "    tweet=tweet.lower()\n",
    "    tweet=tweet.split()\n",
    "    \n",
    "    #Repair gramatically incorrect words \n",
    "    for i in range(len(tweet)):\n",
    "        if d.check(''.join(''.join(s)[:2] for _, s in itertools.groupby(tweet[i]))):\n",
    "            tweet[i]=''.join(''.join(s)[:2] for _, s in itertools.groupby(tweet[i]))\n",
    "        else:\n",
    "            tweet[i]=''.join(''.join(s)[:1] for _, s in itertools.groupby(tweet[i]))\n",
    "    \n",
    "    tweet=' '.join(tweet)\n",
    "    \n",
    "    #Clean using regular expressions\n",
    "    tweet = re.sub(r\"\\'s\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\'ve\", \"ve\", tweet)\n",
    "    tweet = re.sub(r\"n\\'t\", \"nt\", tweet)\n",
    "    tweet = re.sub(r\"\\'re\", \"re\", tweet)\n",
    "    tweet = re.sub(r\"\\'d\", \"d\", tweet)\n",
    "    tweet = re.sub(r\"\\'ll\", \"ll\", tweet)\n",
    "    tweet = re.sub(r\"\\'nt\", \"nt\", tweet)\n",
    "    tweet = re.sub(r\",\", \"\", tweet)\n",
    "    tweet = re.sub(r\"!\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\(\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\)\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\?\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\s{2,}\", \" \", tweet)\n",
    "    #Remove the @ mention\n",
    "    tweet= re.sub(r'@[A-Za-z0-9]+','',tweet)\n",
    "    \n",
    "    #REmove other punctuations\n",
    "    tweet=\"\".join(c for c in tweet if c not in punctuation)\n",
    "     \n",
    "    #Remove hashtag\n",
    "    tweet= re.sub(r'#[A-Za-z0-9]+','',tweet)\n",
    "    \n",
    "    # Remove numbers \n",
    "    liste=[word for word in tweet.split() if not word.isnumeric()]\n",
    "    tweet=' '.join(liste) \n",
    "    \n",
    "    return tweet.strip().lower()\n",
    "\n",
    "\n",
    "\n",
    "def Process_data(data,label):\n",
    "    sentences=[]\n",
    "    labels=[]\n",
    "    \n",
    "    '''This method does the pre-processing for each data set by iterating over the tweets and applying the Process() method'''\n",
    "    \n",
    "    n,m=data.shape\n",
    "    for i in range(n):\n",
    "        line = data.Tweet[i]\n",
    "        line=Process(line)\n",
    "        sentences.append(line)\n",
    "        if label==True:\n",
    "            labels.append(data.label[i])\n",
    "        \n",
    "        d2=pd.DataFrame(sentences,columns=[\"tweets\"])\n",
    "    if label==True:\n",
    "        d1=pd.DataFrame(labels,columns=[\"label\"])\n",
    "        Proc=pd.concat([d1, d2], axis=1)\n",
    "    else:\n",
    "        Proc=d2\n",
    "        \n",
    "    \n",
    "    return Proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.cw'/Users/dlebron/Desktop/Twitter_Proj'\n",
    "\n",
    "#Load and fix the Sentiment 104 Data.\n",
    "X=pd.read_csv(\"training.1600000.processed.noemoticon.csv\",encoding = \"ISO-8859-1\",header=None)\n",
    "X.columns=['label','A','B','C','D','Tweet']\n",
    "X=X.drop([\"A\",\"B\",\"C\",\"D\"],axis=1)\n",
    "n,m=X.shape\n",
    "\n",
    "#Subsample 50,000 observations\n",
    "S=50000\n",
    "d1=X[1:int(S/2)]\n",
    "d2=X[-int(S/2):n]\n",
    "\n",
    "X_sub=pd.concat([d1,d2])\n",
    "X_sub=X_sub[X_sub.label != 2]\n",
    "X_sub=X_sub.reset_index()\n",
    "\n",
    "#Load Trump Data\n",
    "\n",
    "Trump = pd.read_excel(\"2017_01_28TrumpTweets.xlsx\")#30,385\n",
    "X_sub.to_csv(\"Tweets_50k.csv\",header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process and Save the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_proc=Process_data(X_sub,label=True)\n",
    "T_proc=Process_data(Trump,label=False)\n",
    "\n",
    "#Check if url's and mentions are removed \n",
    "\n",
    "T_proc.to_csv(\"Trump_Processed.csv\",header=True)\n",
    "X_proc.to_csv(\"Tweets_50kProc.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub.Tweet[49880]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_proc.tweets[49880]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
